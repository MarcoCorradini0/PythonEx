{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Regressione lineare con Iris (da CSV)\n",
        "\n",
        "Notebook per una lezione di ~4 ore (studenti junior)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Obiettivi della lezione\n",
        "- Capire l’idea di **regressione**: prevedere un numero (variabile continua)\n",
        "- Caricare e ispezionare un dataset da `iris.csv`\n",
        "- Costruire un modello di **regressione lineare** con scikit-learn\n",
        "- Valutare il modello con metriche e grafici (errori, residui)\n",
        "- Estendere a **regressione multipla** e, opzionale, **polinomiale**\n",
        "\n",
        "## Prerequisiti\n",
        "- Python installato\n",
        "- VS Code + estensione Jupyter\n",
        "- File `iris.csv` nella stessa cartella del notebook (oppure aggiorna il path)\n",
        "\n",
        "## Agenda (indicativa)\n",
        "1. Caricamento dati e controlli (30–40 min)\n",
        "2. Esplorazione dati con grafici (50–60 min)\n",
        "3. Regressione lineare semplice: train/test, metriche, grafici (60–70 min)\n",
        "4. Regressione multipla: interpretazione coefficienti, confronto (40–50 min)\n",
        "5. Estensioni e mini-esercizi (30–40 min)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Setup e import\n",
        "Esegui questa cella per importare librerie e impostare alcune opzioni grafiche."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Per rendere i grafici più leggibili\n",
        "plt.rcParams[\"figure.figsize\"] = (9, 5)\n",
        "plt.rcParams[\"axes.grid\"] = True\n",
        "\n",
        "print(\"Setup OK\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Carica `iris.csv`\n",
        "\n",
        "Metti `iris.csv` **nella stessa cartella** di questo notebook.\n",
        "Se il file è altrove, modifica `csv_path`.\n",
        "\n",
        "Nota: Iris nasce come dataset di **classificazione** (specie). Qui lo usiamo per una **regressione**: prevediamo una misura (es. `petal_length`) da altre misure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "csv_path = \"iris.csv\"  # cambia qui se necessario\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Controllo rapido: colonne, tipi, valori mancanti"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "display(df.info())\n",
        "display(df.describe(include=\"all\"))\n",
        "\n",
        "missing = df.isna().sum().sort_values(ascending=False)\n",
        "missing[missing > 0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Pulizia minima e standardizzazione nomi colonne\n",
        "\n",
        "Dataset Iris da CSV spesso ha nomi tipo `sepal_length`, oppure `SepalLengthCm`. Normalizziamo i nomi e facciamo una scelta chiara.\n",
        "\n",
        "Se il tuo CSV ha già nomi puliti, questa cella non fa danni (rinomina solo quando serve)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Normalizza nomi: minuscolo, spazi->underscore\n",
        "df.columns = [c.strip().lower().replace(\" \", \"_\") for c in df.columns]\n",
        "\n",
        "# Rinomine comuni (se presenti)\n",
        "rename_map = {\n",
        "    \"sepallengthcm\": \"sepal_length\",\n",
        "    \"sepalwidthcm\": \"sepal_width\",\n",
        "    \"petallengthcm\": \"petal_length\",\n",
        "    \"petalwidthcm\": \"petal_width\",\n",
        "    \"species\": \"species\"\n",
        "}\n",
        "df = df.rename(columns={c: rename_map[c] for c in df.columns if c in rename_map})\n",
        "\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Esplorazione dati (EDA) con grafici\n",
        "\n",
        "Qui facciamo grafici “belli” e immediati.\n",
        "\n",
        "### 4.1 Distribuzioni (istogrammi)\n",
        "Scegliamo le colonne numeriche e vediamo come sono distribuite."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "num_cols"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "df[num_cols].hist(bins=20)\n",
        "plt.suptitle(\"Distribuzioni delle variabili numeriche\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2 Scatter plot: relazione tra due variabili\n",
        "\n",
        "Per la regressione lineare semplice useremo:\n",
        "- **X = sepal_length**\n",
        "- **y = petal_length**\n",
        "\n",
        "Motivo: c’è spesso una relazione abbastanza lineare e si vede bene a occhio."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "x_col = \"sepal_length\"\n",
        "y_col = \"petal_length\"\n",
        "\n",
        "if x_col not in df.columns or y_col not in df.columns:\n",
        "    raise ValueError(f\"Colonne attese non trovate. Colonne disponibili: {list(df.columns)}\")\n",
        "\n",
        "plt.scatter(df[x_col], df[y_col], alpha=0.7)\n",
        "plt.xlabel(x_col)\n",
        "plt.ylabel(y_col)\n",
        "plt.title(f\"Scatter: {y_col} vs {x_col}\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.3 Correlazioni (heatmap semplice)\n",
        "\n",
        "Non usiamo librerie extra: solo matplotlib."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "corr = df[num_cols].corr(numeric_only=True)\n",
        "\n",
        "plt.imshow(corr.values)\n",
        "plt.xticks(range(len(corr.columns)), corr.columns, rotation=45, ha=\"right\")\n",
        "plt.yticks(range(len(corr.columns)), corr.columns)\n",
        "plt.colorbar()\n",
        "plt.title(\"Matrice di correlazione\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "corr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Regressione lineare semplice (una X → una y)\n",
        "\n",
        "### Idea in 20 secondi\n",
        "Vogliamo una retta:\n",
        "\n",
        "\\[ \\hat{y} = a \\cdot x + b \\]\n",
        "\n",
        "che “passi vicino” ai punti.\n",
        "\n",
        "### Definiamo X e y"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "X = df[[x_col]].copy()   # DataFrame 2D\n",
        "y = df[y_col].copy()     # Series 1D\n",
        "\n",
        "X.shape, y.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.1 Train/Test split\n",
        "\n",
        "Separiamo dati in:\n",
        "- **train**: per allenare\n",
        "- **test**: per valutare in modo onesto"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.25, random_state=42\n",
        ")\n",
        "\n",
        "X_train.shape, X_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.2 Allenamento del modello"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "a = float(model.coef_[0])\n",
        "b = float(model.intercept_)\n",
        "\n",
        "print(\"Modello allenato\")\n",
        "print(f\"y_hat = {a:.3f} * x + {b:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.3 Predizioni e metriche\n",
        "\n",
        "Useremo 3 metriche:\n",
        "- **MAE**: errore medio assoluto (facile da capire)\n",
        "- **RMSE**: penalizza di più gli errori grandi\n",
        "- **R²**: “quanto spiega” il modello (0–1, ma può essere anche negativo se pessimo)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_test)\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"MAE  = {mae:.3f}\")\n",
        "print(f\"RMSE = {rmse:.3f}\")\n",
        "print(f\"R²   = {r2:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.4 Grafico: punti reali + retta prevista\n",
        "\n",
        "Questo è il grafico più “didattico”: i punti e la retta."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Scatter dei dati\n",
        "plt.scatter(X_test[x_col], y_test, label=\"Reale (test)\", alpha=0.7)\n",
        "\n",
        "# Linea della regressione: prendiamo un range di x e calcoliamo y_hat\n",
        "x_line = np.linspace(df[x_col].min(), df[x_col].max(), 100)\n",
        "y_line = model.predict(pd.DataFrame({x_col: x_line}))\n",
        "\n",
        "plt.plot(x_line, y_line, label=\"Retta del modello\")\n",
        "plt.xlabel(x_col)\n",
        "plt.ylabel(y_col)\n",
        "plt.title(\"Regressione lineare semplice: test set + retta\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.5 Grafico: reale vs predetto\n",
        "\n",
        "Se fosse perfetto, i punti starebbero sulla diagonale."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "plt.scatter(y_test, y_pred, alpha=0.7)\n",
        "lims = [min(y_test.min(), y_pred.min()), max(y_test.max(), y_pred.max())]\n",
        "plt.plot(lims, lims)\n",
        "plt.xlabel(\"y reale (test)\")\n",
        "plt.ylabel(\"y predetta\")\n",
        "plt.title(\"Reale vs Predetto\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.6 Residui (errori) e cosa ci dicono\n",
        "\n",
        "Residuo = `y_reale - y_predetta`.\n",
        "\n",
        "Un buon modello ha residui:\n",
        "- centrati attorno a 0\n",
        "- senza pattern evidenti quando li mettiamo contro `x`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "residuals = y_test - y_pred\n",
        "\n",
        "plt.hist(residuals, bins=20)\n",
        "plt.title(\"Distribuzione dei residui (test)\")\n",
        "plt.xlabel(\"Residuo\")\n",
        "plt.ylabel(\"Conteggio\")\n",
        "plt.show()\n",
        "\n",
        "plt.scatter(X_test[x_col], residuals, alpha=0.7)\n",
        "plt.axhline(0)\n",
        "plt.title(\"Residui vs X (test)\")\n",
        "plt.xlabel(x_col)\n",
        "plt.ylabel(\"Residuo\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Mini-esercizio (10–15 min)\n",
        "\n",
        "1. Cambia `x_col` con un’altra colonna numerica (es. `sepal_width`).\n",
        "2. Riesegui le celle dalla sezione 4.2 in poi.\n",
        "3. Confronta MAE / RMSE / R² e i grafici.\n",
        "\n",
        "Domanda: **qual è la migliore singola variabile per prevedere `petal_length`?**\n",
        "\n",
        "Suggerimento: prova 2–3 opzioni, non tutte."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) Regressione multipla (più X → una y)\n",
        "\n",
        "Ora usiamo più colonne come input, ad esempio:\n",
        "- `sepal_length`, `sepal_width`, `petal_width`\n",
        "\n",
        "e teniamo `y = petal_length`.\n",
        "\n",
        "In pratica: la “retta” diventa un **piano/iperpiano**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "feature_cols = [\"sepal_length\", \"sepal_width\", \"petal_width\"]\n",
        "for c in feature_cols + [y_col]:\n",
        "    if c not in df.columns:\n",
        "        raise ValueError(f\"Manca la colonna {c}. Colonne disponibili: {list(df.columns)}\")\n",
        "\n",
        "X2 = df[feature_cols].copy()\n",
        "y2 = df[y_col].copy()\n",
        "\n",
        "X2_train, X2_test, y2_train, y2_test = train_test_split(\n",
        "    X2, y2, test_size=0.25, random_state=42\n",
        ")\n",
        "\n",
        "model2 = LinearRegression()\n",
        "model2.fit(X2_train, y2_train)\n",
        "\n",
        "y2_pred = model2.predict(X2_test)\n",
        "\n",
        "mae2 = mean_absolute_error(y2_test, y2_pred)\n",
        "rmse2 = mean_squared_error(y2_test, y2_pred, squared=False)\n",
        "r2_2 = r2_score(y2_test, y2_pred)\n",
        "\n",
        "print(\"Metriche regressione multipla\")\n",
        "print(f\"MAE  = {mae2:.3f}\")\n",
        "print(f\"RMSE = {rmse2:.3f}\")\n",
        "print(f\"R²   = {r2_2:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7.1 Coefficienti: “quanto pesa” ogni variabile\n",
        "\n",
        "Attenzione: senza normalizzare le feature, i coefficienti dipendono dalle scale.\n",
        "Qui le scale sono simili, quindi è comunque leggibile per una lezione junior."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "coef_table = pd.DataFrame({\n",
        "    \"feature\": feature_cols,\n",
        "    \"coef\": model2.coef_\n",
        "}).sort_values(\"coef\", ascending=False)\n",
        "\n",
        "display(coef_table)\n",
        "\n",
        "plt.bar(coef_table[\"feature\"], coef_table[\"coef\"])\n",
        "plt.title(\"Coefficienti della regressione multipla\")\n",
        "plt.xlabel(\"Feature\")\n",
        "plt.ylabel(\"Coefficiente\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7.2 Grafico: reale vs predetto (multipla)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "plt.scatter(y2_test, y2_pred, alpha=0.7)\n",
        "lims = [min(y2_test.min(), y2_pred.min()), max(y2_test.max(), y2_pred.max())]\n",
        "plt.plot(lims, lims)\n",
        "plt.xlabel(\"y reale (test)\")\n",
        "plt.ylabel(\"y predetta\")\n",
        "plt.title(\"Reale vs Predetto (regressione multipla)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8) Confronto semplice: modello 1 vs modello 2\n",
        "\n",
        "Quale generalizza meglio?\n",
        "\n",
        "Ricorda: un modello con più feature *può* migliorare, ma non è garantito."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "comparison = pd.DataFrame([\n",
        "    {\"modello\": \"Semplice (sepal_length -> petal_length)\", \"MAE\": mae, \"RMSE\": rmse, \"R2\": r2},\n",
        "    {\"modello\": \"Multipla (3 feature -> petal_length)\", \"MAE\": mae2, \"RMSE\": rmse2, \"R2\": r2_2},\n",
        "])\n",
        "comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9) Estensione opzionale: regressione polinomiale (sezione “wow”)\n",
        "\n",
        "Se gli studenti sono molto junior, questa parte può essere solo dimostrativa.\n",
        "\n",
        "Idea: aggiungiamo `x²` per permettere una curva.\n",
        "\n",
        "Useremo **solo numpy** (senza pipeline) per restare leggibili."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Regressione polinomiale di grado 2: y_hat = a2*x^2 + a1*x + b\n",
        "X_poly = pd.DataFrame({\n",
        "    x_col: df[x_col],\n",
        "    f\"{x_col}^2\": df[x_col] ** 2\n",
        "})\n",
        "y_poly = df[y_col]\n",
        "\n",
        "Xp_train, Xp_test, yp_train, yp_test = train_test_split(\n",
        "    X_poly, y_poly, test_size=0.25, random_state=42\n",
        ")\n",
        "\n",
        "modelp = LinearRegression()\n",
        "modelp.fit(Xp_train, yp_train)\n",
        "yp_pred = modelp.predict(Xp_test)\n",
        "\n",
        "maep = mean_absolute_error(yp_test, yp_pred)\n",
        "rmsep = mean_squared_error(yp_test, yp_pred, squared=False)\n",
        "r2p = r2_score(yp_test, yp_pred)\n",
        "\n",
        "print(\"Metriche polinomiale (grado 2)\")\n",
        "print(f\"MAE  = {maep:.3f}\")\n",
        "print(f\"RMSE = {rmsep:.3f}\")\n",
        "print(f\"R²   = {r2p:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Grafico: dati + curva (usiamo il modello polinomiale)\n",
        "plt.scatter(df[x_col], df[y_col], alpha=0.5, label=\"Dati\")\n",
        "\n",
        "x_line = np.linspace(df[x_col].min(), df[x_col].max(), 200)\n",
        "X_line_poly = pd.DataFrame({x_col: x_line, f\"{x_col}^2\": x_line**2})\n",
        "y_line = modelp.predict(X_line_poly)\n",
        "\n",
        "plt.plot(x_line, y_line, label=\"Curva polinomiale (grado 2)\")\n",
        "plt.xlabel(x_col)\n",
        "plt.ylabel(y_col)\n",
        "plt.title(\"Regressione polinomiale (dimostrazione)\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10) Esercizi finali (30–40 min)\n",
        "\n",
        "1. Cambia la variabile target `y_col` in `petal_width` e ripeti i modelli.\n",
        "2. Prova un diverso split train/test (es. `test_size=0.3`) e osserva come cambiano le metriche.\n",
        "3. (Bonus) Aggiungi una feature in `feature_cols` e osserva l’impatto.\n",
        "\n",
        "Obiettivo: collegare **scelte** (feature, target, split) a **risultati** (metriche e grafici)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11) Riepilogo\n",
        "\n",
        "- La regressione lineare prova a descrivere una relazione con una formula semplice.\n",
        "- La valutazione va fatta su dati non visti (test set).\n",
        "- Grafici e residui aiutano a capire se il modello “ha senso”.\n",
        "- Più feature possono aiutare, ma vanno valutate.\n",
        "\n",
        "Fine."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}